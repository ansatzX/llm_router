# LLM Router Configuration

# Base URL of the LLM backend (e.g., SGLang, vLLM, or any OpenAI-compatible API)
LLM_BASE_URL=http://localhost:8000

# API Key for the LLM backend (if required, leave empty if not needed)
LLM_API_KEY=

# Port for the Flask router (default: 5001)
FLASK_PORT=5001

# ============================================================================
# Model Capability Configuration
# ============================================================================

# Model type: "text" or "multimodal"
# - text: Text-only model. Images/documents will be rejected with instructions
#         to use local tools (like MCP).
# - multimodal: Can process images directly. Documents will still be rejected
#               with instructions to use local tools.
MODEL_TYPE=text

# Maximum file size for uploads (in MB). Files larger than this will be rejected.
MAX_UPLOAD_SIZE_MB=10

# When a text model receives an image/document, return this message:
TEXT_MODEL_MEDIA_PROMPT=This model cannot process images or documents. Please use a local tool (e.g., MCP tool) to analyze the content and pass the results as text.

# When a multimodal model receives a document (not image), return this message:
MULTIMODAL_MODEL_DOCUMENT_PROMPT=This model cannot process documents directly. Please use a local tool (e.g., MCP tool) to extract the content and pass it as text.
